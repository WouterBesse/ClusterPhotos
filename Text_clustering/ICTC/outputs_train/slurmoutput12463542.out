============================================================================================== 
Warning! Mixing Conda and module environments may lead to corruption of the
user environment. 
We do not recommend users mixing those two environments unless absolutely
necessary. Note that 
SURF does not provide any support for Conda environment.
For more information, please refer to our software policy page:
https://servicedesk.surf.nl/wiki/display/WIKI/Software+policy+Snellius#SoftwarepolicySnellius-UseofAnacondaandMinicondaenvironmentsonSnellius 

Remember that many packages have already been installed on the system and can
be loaded using 
the 'module load <package__name>' command. If you are uncertain if a package is
already available 
on the system, please use 'module avail' or 'module spider' to search for it.
============================================================================================== 
[2025-06-17 19:59:39,266] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/home/scur0274/.conda/envs/ictc/lib/python3.10/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Traceback (most recent call last):
  File "/gpfs/home3/scur0274/Text_clustering/ICTC/step2a.py", line 53, in <module>
    tokenizer = AutoTokenizer.from_pretrained(llama_model, use_auth_token=True)
  File "/home/scur0274/.conda/envs/ictc/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py", line 652, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
  File "/home/scur0274/.conda/envs/ictc/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py", line 496, in get_tokenizer_config
    resolved_config_file = cached_file(
  File "/home/scur0274/.conda/envs/ictc/lib/python3.10/site-packages/transformers/utils/hub.py", line 417, in cached_file
    resolved_file = hf_hub_download(
  File "/home/scur0274/.conda/envs/ictc/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "/home/scur0274/.conda/envs/ictc/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 970, in hf_hub_download
    hf_headers = build_hf_headers(
  File "/home/scur0274/.conda/envs/ictc/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py", line 101, in inner_f
    return f(*args, **kwargs)
  File "/home/scur0274/.conda/envs/ictc/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "/home/scur0274/.conda/envs/ictc/lib/python3.10/site-packages/huggingface_hub/utils/_headers.py", line 126, in build_hf_headers
    token_to_send = get_token_to_send(token)
  File "/home/scur0274/.conda/envs/ictc/lib/python3.10/site-packages/huggingface_hub/utils/_headers.py", line 159, in get_token_to_send
    raise LocalTokenNotFoundError(
huggingface_hub.errors.LocalTokenNotFoundError: Token is required (`token=True`), but no token found. You need to provide a token or be logged in to Hugging Face with `huggingface-cli login` or `huggingface_hub.login`. See https://huggingface.co/settings/tokens.

JOB STATISTICS
==============
Job ID: 12463542
Cluster: snellius
User/Group: scur0274/scur0274
State: FAILED (exit code 1)
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:09
CPU Efficiency: 3.57% of 00:04:12 core-walltime
Job Wall-clock time: 00:00:14
Memory Utilized: 1.51 MB
Memory Efficiency: 0.00% of 120.00 GB (120.00 GB/node)
